# ğŸ¨ I'm Something of a Painter Myself â€” Monet Style Transfer
### Unified Implementation of CycleGAN Â· CUT Â· AttentionGAN

This repository contains a complete solution for the Kaggle competition  
**â€œIâ€™m Something of a Painter Myselfâ€**, which focuses on generating Monet-style
paintings from natural photos using *unpaired image-to-image translation*.

We reconstruct and unify three representative GAN models:

- **CycleGAN** (ICCV 2017)
- **CUT â€“ Contrastive Unpaired Translation** (ECCV 2020)
- **AttentionGAN** (WACV 2021)

---

## ğŸ† Competition Performance

Our team achieved a **final score of 36.94468** on the leaderboard, ranking:

# ğŸ‰ **4th out of 170 teams (Top 2%)**

This reflects strong model performance and stability across multiple architectures.

> *(Score and ranking were recorded during project reporting; leaderboard may later change depending on competition timeline.)*

---

## ğŸš€ Overview

The objective is to train models that generate 7,000â€“10,000 Monet-style images  
(256Ã—256 RGB) for submission.

The dataset consists of:

- Monet paintings (`monet_jpg`, `monet_tfrec`)
- Natural photos (`photo_jpg`, `photo_tfrec`)

Evaluation uses **FID** and **MI-FID**, measuring the distance between the
distribution of generated images and real Monet images.

---

## ğŸ“‚ Project Structure
```
painter/
â”œâ”€â”€ data/                 # dataset placeholder; real data not included
â”œâ”€â”€ imgs/                 # images for documentation (optional)
â”œâ”€â”€ notebooks/            # Kaggle submission & analysis notebooks
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/           # unified CycleGAN / CUT / AttentionGAN models
â”‚   â”œâ”€â”€ datasets/         # dataset loading utilities
â”‚   â”œâ”€â”€ util/             # training utilities (logging, losses, etc.)
â”‚   â”œâ”€â”€ train_cyclegan.py
â”‚   â”œâ”€â”€ train_cut.py
â”‚   â”œâ”€â”€ train_attngan.py
â”‚   â”œâ”€â”€ test_cyclegan.py
â”‚   â”œâ”€â”€ test_cut.py
â”‚   â””â”€â”€ test_attngan.py
â”œâ”€â”€ README.md
â””â”€â”€ README_zh.md
```
---

## ğŸ§  Models

### **1ï¸âƒ£ CycleGAN**
CycleGAN performs unpaired translation using:

- Generatorâ€“Discriminator pairs  
- Cycle consistency loss  
- Least-squares GAN loss (LSGAN)

ğŸ’¡ *Observations during training*  
CycleGAN is sensitive to learning rate decay and requires batch size = 1,
consistent with official implementations.

ğŸ“ *(Insert training curves using external links if desired)*  
Example:  
![CycleGAN FID Curve](https://via.placeholder.com/600x300?text=CycleGAN+FID+Curve)

---

### **2ï¸âƒ£ CUT (Contrastive Unpaired Translation)**

CUT replaces cycle-consistency with **PatchNCE contrastive loss**, allowing
stronger content preservation.

Key advantages:

- Faster convergence  
- Better structure retention  
- Works well on style transfer tasks with strong texture changes  

ğŸ“ *(Insert visual comparison via URL)*  
![CUT Architecture](https://via.placeholder.com/600x300?text=CUT+Architecture)

---

### **3ï¸âƒ£ AttentionGAN**

AttentionGAN enhances translation using:

- Spatial attention  
- Channel attention  
- Region-level style learning  

This often yields more aesthetically pleasing Monet strokes and textures.

ğŸ“ Example placeholder:  
![AttentionGAN](https://via.placeholder.com/600x300?text=AttentionGAN+Example)

---

## ğŸ“Š Results Summary

| Model         | Strengths                               | Weaknesses                          |
|---------------|------------------------------------------|--------------------------------------|
| **CycleGAN**  | Strong global style transfer             | Unstable training, sensitive to LR   |
| **CUT**       | Best content preservation                | Sometimes less stylized              |
| **AttentionGAN** | Finest local texture & color details | Training more computationally heavy  |

Final generated images demonstrate that all three methods can produce Monet-style transformations with different emphases on texture, structure, and artistic abstraction.

ğŸ“ Insert comparison (optional):  
![Comparison Grid](https://via.placeholder.com/800x350?text=Method+Comparison)

---

## ğŸ› ï¸ How to Train

### **CycleGAN**
```bash
python src/train_cyclegan.py
```
### **CUT**
```bash
python src/train_cut.py
```
### **AttentionGAN**
```bash
python src/train_attngan.py
```

â¸»

ğŸ™ Acknowledgements

This project builds on the outstanding work of these open-source implementations:
	â€¢	CycleGAN â€“ Zhu et al., ICCV 2017
https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
	â€¢	CUT â€“ Park et al., ECCV 2020
https://github.com/taesungp/contrastive-unpaired-translation
	â€¢	AttentionGAN â€“ Tang et al., WACV 2021
https://github.com/Ha0Tang/AttentionGAN